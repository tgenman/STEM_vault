---
created: 2025-04-16 20:02
doi: https://doi.org/10.48550/arXiv.2408.04532
author: 
tags:
  - content/paper
---
Xingwu Chen, Lei Zhao, and Difan Zou.

```
@misc{chen2024transformersutilizemultiheadattention,
      title={How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression}, 
      author={Xingwu Chen and Lei Zhao and Difan Zou},
      year={2024},
      eprint={2408.04532},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.04532}, 
}
```