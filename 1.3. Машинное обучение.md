


**2. Core Concepts and Terminology:**

These seemingly diverse problems share common characteristics:

- **Mapping Objects to Predictions:** Their solutions can be expressed as a function that maps "objects" or "samples" to "predictions" or "targets." For example, patients are mapped to diagnoses, and documents to relevance scores.
- **Lack of a Single Perfect Solution:** These problems often don't have a single, definitively correct answer. Different translations can be valid, and doctors can make different diagnoses. The pursuit of a flawless solution can be counterproductive.
- **Availability of Training Data:** We typically have access to many examples of correct answers (e.g., translated sentences, image captions). Incorrect examples, if needed, are usually easy to generate.

The authors introduce key terminology:
- [[Model (ML)]]
- [[Training Dataset]]

**3. Types of Machine Learning Problems (Supervised Learning):**

The document focuses primarily on **supervised learning**, where the correct answers for each object in the training dataset are known beforehand. Supervised learning tasks are categorised based on the nature of the target variable:

- **Regression:** Predicting a continuous numerical value (e.g., car-sharing trip duration, product demand, tomorrow's weather). The target set is the set of real numbers (‚Ñù) or a subset thereof.
- **Binary Classification:** Predicting one of two possible categories (e.g., whether a user will click on an ad, whether a customer will repay a loan, whether an image contains a banana). The target set is {0, 1} or {-1, +1}.
- **Multiclass Classification:** Predicting one of several discrete, mutually exclusive categories (e.g., the subject area of a scientific article). The target set is {1, ..., N}, where N is the number of classes.
- **Multilabel Classification:** Predicting multiple non-exclusive categories for a single object (e.g., assigning tags to a restaurant).
- **Ranking:** Ordering a set of objects based on their relevance to a query (e.g., search engine results). The target set is a finite, ordered set.

The text also briefly mentions more complex tasks like image segmentation and machine translation, where the output is more structured (e.g., a segmented image, a translated sentence). Furthermore, it introduces the concept of **generative models**, which aim to create new, plausible objects.

**4. Unsupervised Learning:**

In contrast to supervised learning, **unsupervised learning** deals with problems where only the data is known, and the answers are either unknown or do not exist. The goal is often not to predict a specific target but to discover underlying patterns in the data. A classic example is **clustering**, where objects are grouped based on their inherent similarities.

**5. Reinforcement Learning:**

While not detailed in this excerpt, the document briefly mentions **reinforcement learning** as a paradigm where a model learns through interaction with an environment, receiving rewards or penalties based on its actions. The example of teaching a robot cat to jump onto a table illustrates this.

**6. Quality Criteria (Metrics):**

The authors emphasise the importance of defining **quality metrics** to evaluate the performance of machine learning models. They distinguish between:

- **Business Metrics:** High-level metrics related to the overall goals of the project (e.g., service revenue). These are often difficult to measure directly.
- **Online Metrics:** Characteristics of a running system that are hoped to correlate with business metrics (e.g., median session length in a game, average stock levels).
- **Offline Metrics:** Metrics that can be measured before deploying a model, often using historical data. For prediction tasks, these typically assess the deviation of the model's predictions from the true targets (e.g., accuracy, mean squared error). **Assessor evaluation** (evaluation by human experts) is also considered an offline metric.

The text provides examples of relevant offline metrics for different supervised learning tasks, such as the proportion of correctly diagnosed cases for medical diagnosis, and the proportion of correctly ordered document pairs for ranking. It stresses that the choice of metric depends on the specific needs and priorities of the customer or application.

The "Question to Think About" sections throughout this part encourage the reader to consider how different scenarios might necessitate different evaluation metrics (e.g., the importance of precision vs. recall in medical diagnosis depending on the severity and impact of a false positive or false negative).

Beyond metrics, the document also highlights other important quality criteria:

- **Real-time prediction capability**
- **Model compactness** (for deployment on devices)
- **Explainability/Interpretability** of predictions
- **Fairness** and lack of discrimination against user categories

**7. Data: The Foundation of Machine Learning:**

The chapter underscores that machine learning starts with data. Sufficient quantity and high quality of data are crucial for success. The authors discuss challenges related to data availability and quality:

- **Data Scarcity:** Obtaining enough labelled data can be a significant hurdle. They mention approaches like **crowdsourcing** and **citizen science** for data annotation, as well as **self-supervised learning** techniques that leverage unlabelled data. **Representation learning**, the task of creating compact and meaningful representations of complex data, is highlighted as a key aspect of self-supervised learning.
- **Data Quality Issues:Missing Values (NaNs):** How to handle incomplete data.
- **Outliers:** Anomalous data points that can skew model training.
- **Labelling Errors:** Incorrectly annotated targets.
- **Data Drift:** Changes in the data distribution or collection process over time.
- **Concept Drift:** Changes in the underlying relationship between features and the target variable.

The importance of **features** (the properties used by the model) and **feature engineering** (the process of extracting informative features from raw data) is also discussed. The concept of representing data in a **tabular format** (objects as rows, features as columns) and the resulting **object-feature matrix** is introduced as a convenient structure for analysis, especially when features are numerical.

**8. Model and Learning Algorithm:**

The document explains that a **model** is a way of describing the world, often a predictive model that attempts to capture the relationship between an object's features and its target. These models are often part of a **parametric family**, where the specific model is determined by its parameters.

The process of finding the optimal parameters based on the training data is called **learning** or **training**, and the procedure used is the **learning algorithm**. The text illustrates this with a simple example of predicting apartment prices using a constant function as the model and Mean Absolute Error (MAE) and Mean Squared Error (MSE) as different quality metrics, demonstrating how different metrics lead to different optimal parameter values (median for MAE, mean for MSE).

It mentions that while many practical problems today are solved using gradient boosting on decision trees and neural networks, understanding other model types is important for a deeper understanding and for future innovation.

The selection of a **loss function** (a differentiable function that approximates the desired metric) is crucial when the evaluation metric itself is not differentiable (e.g., accuracy). The **gradient descent** algorithm is introduced as a common method for minimising loss functions by iteratively adjusting model parameters in the direction of the negative gradient. The **learning rate** (a hyperparameter of the algorithm) plays a significant role in the training process.

**9. Model Selection and Overfitting:**

The chapter addresses the crucial issue of **overfitting**, where a model learns the training data too well, including its noise, and performs poorly on unseen data. This is contrasted with **generalisation**, the ability of a model to learn underlying patterns and make accurate predictions on new data.

To mitigate overfitting, the common practice of splitting the data into a **training set** and a **test set** is introduced. The model is trained on the training set, and its performance is evaluated on the held-out test set to estimate its generalisation ability.

The relationship between model complexity and performance is illustrated with graphs showing that as model complexity increases, the error on the training set typically decreases, but the error on the test set may initially decrease and then start to increase again, indicating overfitting. The document notes that for deep learning models, this behaviour can be more nuanced.

The reader is cautioned against simply memorising the training data and is advised to always evaluate models on a separate test set. The complexity of a model is tentatively described as the number of its adjustable parameters, although more rigorous definitions exist.

**10. After Training (Deployment and Monitoring):**

The final section outlines the steps involved after a model has been trained:

- **Deployment:** The process of making the trained model operational in a production environment, including coding, parallelisation, and integration with existing systems.
- **A/B Testing:** Comparing the new model against a previous version on randomly selected subsets of users to assess its real-world impact.
- **Monitoring:** Continuously tracking the model's performance and the characteristics of the incoming data to detect issues like **data drift** and **concept drift**, which may necessitate retraining or updating the model.

The chapter concludes by encouraging the reader to engage with practical exercises and the community to further their learning.

In summary, this introductory chapter provides a comprehensive overview of the fundamental concepts in machine learning, from defining what it is and the types of problems it tackles, to the importance of data, evaluation metrics, model selection, and the practical considerations of deployment and monitoring. It lays a solid foundation for understanding the more technical details that will likely follow in subsequent chapters.

---

### Frequently Asked Questions about Machine Learning

#### What is the fundamental definition of machine learning, and what are some examples of tasks it excels at that are difficult for traditional programming?

Machine learning is defined as "the science that studies algorithms that automatically improve through experience." It involves creating models that can learn from data without being explicitly programmed. Examples of tasks where machine learning proves highly effective, yet are challenging to program directly, include: translating text between languages, diagnosing diseases based on symptoms, determining the relevance of online documents to a search query, identifying objects in images, and estimating property prices. These tasks share the commonality of mapping inputs to outputs where a single perfect solution is often elusive and where ample training data is typically available.

#### What are the core components involved in a supervised machine learning problem?

In supervised learning, the core components are the **model**, which is the function that maps objects to predictions, and the **training dataset**. The training dataset consists of **objects** (also referred to as samples or examples) which are the inputs to the model (e.g., images, patient histories), and their corresponding **answers** or **targets** (e.g., image captions, diagnoses), which are the desired outputs for those objects. The goal of supervised learning is for the model to learn the relationship between the objects and their targets from this data.

#### What are the main categories of supervised learning tasks, and how do they differ based on the nature of the target variable?

Supervised learning tasks are categorised by the type of target variable being predicted. The main categories include:

- **Regression:** Predicting a continuous numerical value (e.g., temperature).
- **Binary Classification:** Predicting one of two discrete categories (e.g., spam or not spam).
- **Multiclass Classification:** Predicting one of several mutually exclusive discrete categories (e.g., cat, dog, or bird).
- **Multilabel Classification:** Predicting multiple non-exclusive categories (e.g., tags for a movie like action, comedy, and thriller).
- **Ranking:** Ordering a set of objects based on their relevance (e.g., search results). More complex tasks like image segmentation and machine translation, as well as generative models that create new data instances, also fall under the broader umbrella of machine learning.

#### How does unsupervised learning differ from supervised learning, and what is a typical goal in unsupervised learning?

Unsupervised learning deals with data where the correct answers or targets are unknown or do not exist. Unlike supervised learning, the primary goal is not to make specific predictions but rather to discover underlying patterns, structures, or relationships within the data itself. A classic example of unsupervised learning is clustering, where objects are grouped together based on their similarities without any prior knowledge of what those groups should be.

#### Why are quality criteria and metrics crucial in machine learning, and what are the different types of metrics discussed?

Quality criteria and metrics are essential for evaluating the performance of machine learning models and determining if they are "good enough" for their intended purpose. The document distinguishes between:

- **Business Metrics:** High-level metrics related to business goals (e.g., revenue).
- **Online Metrics:** Characteristics of a running system that hopefully correlate with business metrics (e.g., user engagement time).
- **Offline Metrics:** Metrics measured before deployment using historical data to assess the model's predictive accuracy (e.g., accuracy, mean squared error) or through human evaluation (assessor evaluation). The choice of metric depends heavily on the specific problem and the priorities of the application or customer.

#### Why is data considered the foundation of machine learning, and what are some key challenges related to data quality and availability?

Data is fundamental to machine learning because models learn patterns and improve through experience derived from data. Sufficient quantity and high quality of data are critical for building effective models. Key challenges include:

- **Data Scarcity:** Difficulty in obtaining enough labelled data.
- **Missing Values (NaNs):** Incomplete data points.
- **Outliers:** Anomalous data that can distort training.
- **Labelling Errors:** Incorrectly annotated targets.
- **Data Drift:** Changes in the data distribution over time.
- **Concept Drift:** Changes in the underlying relationship between features and the target. Addressing these challenges often involves techniques like data augmentation, imputation, outlier detection, and continuous monitoring.

#### What are the roles of a model and a learning algorithm in machine learning, and what is the significance of a loss function and gradient descent?

A **model** is a way of describing the relationship between an object's features and its target, often part of a parametric family defined by adjustable parameters. A **learning algorithm** is the procedure used to find the optimal values for these parameters based on the training data. A **loss function** is a differentiable function that approximates the desired evaluation metric, especially when the metric itself is not differentiable (e.g., accuracy). **Gradient descent** is a common optimisation algorithm used to minimise the loss function by iteratively adjusting the model's parameters in the direction that reduces the loss. The learning rate, a hyperparameter of gradient descent, controls the size of these adjustments.

#### What is overfitting, and how is the concept of a training and test set used to address this issue?

Overfitting occurs when a model learns the training data too well, including its noise and random fluctuations, and consequently performs poorly on new, unseen data. To mitigate overfitting, the data is typically split into a **training set** and a **test set**. The model is trained on the training set, and its performance is evaluated on the held-out test set to estimate its ability to generalise to new data. A significant discrepancy between the model's performance on the training and test sets can indicate overfitting, where the model has essentially memorised the training data rather than learning underlying patterns.


---

## Machine Learning Study Guide

### Quiz

1. Define machine learning in your own words, drawing on the provided text. Provide an example of a task that is easy for humans but difficult to program explicitly, as mentioned in the source material.
2. Explain the difference between supervised and unsupervised learning. Give a specific example of a task that falls under each category based on the briefing documents.
3. Describe the core components of a supervised machine learning problem. What role does the training dataset play in this process?
4. List and briefly define three distinct categories of supervised learning tasks based on the nature of the target variable. Provide a simple example for each.
5. Why are quality metrics important in machine learning? Differentiate between offline and online metrics, providing an example of each.
6. Explain why data is considered the foundation of machine learning. Describe two key challenges related to data quality or availability mentioned in the texts.
7. What is the role of a model in machine learning? How does a learning algorithm interact with a model and the training data?
8. Define the concept of a loss function and explain its significance in the context of training a machine learning model. What is the purpose of gradient descent?
9. Explain the phenomenon of overfitting in machine learning. How does the use of a training set and a test set help to identify and mitigate overfitting?
10. Briefly outline the typical steps involved after a machine learning model has been trained, focusing on deployment and monitoring. What is the significance of A/B testing?

### Quiz Answer Key

1. Machine learning is the scientific discipline focused on creating algorithms that can automatically improve their performance through experience gained from data. An example of a task that humans find relatively easy but is hard to program explicitly is translating text between different languages.
2. Supervised learning involves training a model on a dataset where the correct answers (targets) for each input object are known beforehand, allowing the model to learn a mapping from inputs to outputs (e.g., classifying emails as spam or not spam). Unsupervised learning, on the other hand, deals with data where the targets are unknown or non-existent, and the goal is to discover underlying patterns or structures in the data (e.g., clustering customers into different groups based on their purchasing behaviour).
3. The core components of supervised learning are the model, which is the function that maps objects to predictions, and the training dataset, which is a collection of objects paired with their corresponding correct answers or targets. The training dataset is crucial as it provides the "experience" from which the model learns the relationship between inputs and desired outputs.
4. Three categories of supervised learning tasks are:

- **Regression:** Predicting a continuous numerical value, such as estimating the price of a house based on its features.
- **Binary Classification:** Predicting one of two possible categories, for instance, determining whether a customer will click on an online advertisement.
- **Multiclass Classification:** Predicting one of several discrete, mutually exclusive categories, like identifying the type of animal (cat, dog, bird) in an image.

1. Quality metrics are essential in machine learning to quantitatively evaluate the performance of a model and determine if it is meeting the desired objectives. Offline metrics are measured before deploying a model, often using historical data to assess its predictive accuracy (e.g., the accuracy of a medical diagnosis model on a past patient dataset). Online metrics are characteristics of a running system used to infer how the model impacts business goals (e.g., the average time users spend on a website after interacting with a recommendation system).
2. Data is the foundation of machine learning because models learn patterns and improve their ability to make predictions based on the information contained within the data they are trained on. Two key challenges related to data are data scarcity, where there isn't enough labelled data to effectively train a model, and data drift, where the statistical properties of the data change over time, potentially leading to a decrease in model performance.
3. A model in machine learning is a representation or a function that aims to capture the relationship between an object's features and its target variable, allowing for predictions to be made. A learning algorithm is the procedure used to adjust the parameters of the model based on the training data, with the goal of optimising the model's performance according to a chosen metric.
4. A loss function is a differentiable function that quantifies the difference between a model's predictions and the true target values in the training data. Its significance lies in providing a mathematical objective that the learning algorithm can attempt to minimise during training, indirectly optimising the desired evaluation metric (especially when the metric itself is not differentiable). Gradient descent is an iterative optimisation algorithm used to find the minimum of a loss function by repeatedly adjusting the model's parameters in the direction of the negative gradient of the loss.
5. Overfitting occurs when a model learns the training data too well, including its noise and specific patterns that do not generalise to new, unseen data, resulting in poor performance on these new data points. To address this, the available data is split into a training set, used to train the model, and a separate test set, used to evaluate the model's ability to generalise to unseen data. A large difference in performance between the training and test sets can indicate overfitting.
6. After training a model, the typical steps include deployment, which is the process of making the model operational in a production environment, and monitoring, which involves continuously tracking the model's performance and the characteristics of incoming data for issues like data drift or concept drift. A/B testing is a method used after deployment to compare the performance of the new model against a previous version by exposing different subsets of users to each and measuring their impact on relevant metrics.

### Essay Format Questions

1. Discuss the fundamental challenges that make tasks like language translation or medical diagnosis difficult to program using traditional, rule-based approaches, and explain how machine learning offers a potential solution to these challenges.
2. Compare and contrast the different categories of supervised learning problems (regression, binary classification, multiclass classification, multilabel classification, ranking), highlighting the key distinctions based on the nature of the target variable and providing real-world examples for each.
3. Evaluate the importance of quality criteria and metrics in the development and deployment of machine learning models. Discuss the different types of metrics (business, online, offline) and explain how the choice of metric can significantly impact the model development process and its ultimate success.
4. Critically analyse the statement "Data is the foundation of machine learning." Discuss the various challenges related to data quality and availability, and explore the techniques and strategies that can be employed to mitigate these issues and ensure the development of robust and reliable machine learning models.
5. Explain the concepts of model selection, overfitting, and generalisation in machine learning. Discuss the relationship between model complexity and performance on training and test data, and elaborate on the strategies used to prevent overfitting and ensure good generalisation ability of a trained model.

### Glossary of Key Terms

- **Algorithm:** A set of well-defined instructions for performing a task or solving a problem. In machine learning, these algorithms enable computers to learn from data.
- **Assessor Evaluation:** An offline quality metric where human experts (assessors) evaluate the performance of a machine learning model based on subjective criteria, such as the quality of machine translation or the relevance of search results.
- **A/B Testing:** A method of comparing two versions of a system or model (A and B) by showing them to randomly selected subsets of users and analysing which version performs better based on predefined metrics.
- **Binary Classification:** A supervised learning task where the goal is to predict one of two possible discrete categories (e.g., yes/no, spam/not spam).
- **Business Metrics:** High-level metrics that reflect the overall goals and success of a business or application (e.g., revenue, customer satisfaction). These are often indirectly influenced by machine learning models.
- **Clustering:** An unsupervised learning technique that groups data points into clusters based on their similarity, without prior knowledge of the group labels.
- **Concept Drift:** A phenomenon where the underlying relationship between the input features and the target variable changes over time, potentially degrading the performance of a deployed machine learning model.
- **Crowdsourcing:** The practice of obtaining data or completing tasks by enlisting a large number of people, often online, to contribute (e.g., for data annotation or labelling).
- **Data Drift:** A phenomenon where the statistical distribution of the input data changes over time, which can affect the performance of a machine learning model trained on older data.
- **Dataset (Training Dataset):** A collection of data examples used to train a machine learning model. In supervised learning, it consists of objects (inputs) and their corresponding answers or targets (outputs).
- **Deployment:** The process of making a trained machine learning model operational in a production environment, where it can be used to make predictions on new data.
- **Feature Engineering:** The process of selecting, transforming, and creating informative features (input variables) from raw data that can improve the performance of a machine learning model.
- **Features:** The individual measurable properties or characteristics of an object that are used as inputs by a machine learning model (e.g., the colour of a pixel in an image, the frequency of a word in a text).
- **Generative Models:** Machine learning models that aim to learn the underlying probability distribution of the training data so that they can generate new, plausible data samples that resemble the original data.
- **Generalisation:** The ability of a machine learning model to learn underlying patterns from the training data and apply this knowledge to make accurate predictions on new, unseen data.
- **Gradient Descent:** An iterative optimisation algorithm used to find the minimum of a differentiable function (often a loss function in machine learning) by repeatedly moving in the direction of the negative gradient.
- **Learning Algorithm:** The specific procedure or method used to train a machine learning model by adjusting its parameters based on the training data.
- **Learning Rate:** A hyperparameter of the gradient descent algorithm that controls the size of the steps taken during each iteration to minimise the loss function.
- **Loss Function:** A mathematical function that quantifies the error or difference between a machine learning model's predictions and the true target values. The goal of training is to minimise this function.
- **Machine Learning:** The science that studies algorithms that automatically improve through experience (data).
- **Model:** A function or structure that learns patterns from data and maps objects (inputs) to predictions (outputs). It represents the learned relationship between features and the target variable.
- **Monitoring:** The ongoing process of tracking the performance of a deployed machine learning model and the characteristics of the incoming data to detect potential issues like data drift or concept drift.
- **Multiclass Classification:** A supervised learning task where the goal is to predict one of several discrete, mutually exclusive categories.
- **Multilabel Classification:** A supervised learning task where the goal is to predict multiple non-exclusive categories for a single object.
- **Offline Metrics:** Quality metrics that are measured using historical data before a model is deployed to evaluate its performance (e.g., accuracy, precision, recall, mean squared error).
- **Online Metrics:** Characteristics of a running, deployed machine learning system that are hoped to correlate with business metrics (e.g., click-through rates, session duration).
- **Outliers:** Data points that significantly deviate from the majority of the data and may be due to errors or represent genuine anomalies.
- **Overfitting:** A phenomenon where a machine learning model learns the training data too well, including its noise and specific patterns, leading to poor performance on new, unseen data.
- **Parametric Family:** A set of models where each specific model is determined by a set of parameters. The learning process involves finding the optimal values for these parameters.
- **Ranking:** A supervised learning task where the goal is to order a set of objects based on their relevance to a given query or criterion.
- **Regression:** A supervised learning task where the goal is to predict a continuous numerical value.
- **Reinforcement Learning:** A machine learning paradigm where an agent learns to make decisions in an environment by receiving rewards or penalties based on its actions.
- **Representation Learning:** A subfield of machine learning focused on learning useful and compact representations of raw data that make it easier to extract information for downstream tasks.
- **Self-Supervised Learning:** A type of machine learning where the model learns from unlabelled data by creating its own supervisory signals from the data itself to solve a pretext task. The learned representations can then be used for downstream supervised tasks.
- **Supervised Learning:** A type of machine learning where a model learns from labelled data, consisting of input objects and their corresponding correct output targets. The goal is to learn a mapping from inputs to outputs.
- **Targets (Answers):** The desired output values or labels associated with the input objects in a supervised learning dataset.
- **Test Set:** A subset of the data that is held out during the training process and used to evaluate the generalisation performance of a trained machine learning model on unseen data.
- **Unsupervised Learning:** A type of machine learning where the model learns from unlabelled data without explicit target variables. The goal is often to discover hidden patterns or structures in the data.

convert_to_textConvert to source

NotebookLM can be inaccurate; please double-check its responses.