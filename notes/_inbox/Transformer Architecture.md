---
aliases: 
publish: true
created: 2024-12-10 10:24
parent:
  - "[[Deep Learning MOC]]"
connected:
  - "[[Mechanistic Interpretability]]"
  - "[[Memformer]]"
tags:
---




- [Transformer Circuits Thread (Antropic)](https://transformer-circuits.pub/)
	- [A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)
	- [Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html#phase-change) is [[Superposition (ml)]]
	- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html)  [[Mechanistic Interpretability]] [[Sparse autoencoder]]

- [[ðŸ‘¤ Andrej Karpathy]]
	- [Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)
	- [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g)
	- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE)
	- [Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU)