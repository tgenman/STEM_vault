---
aliases:
  - TF-IDF
anki: false
created: 2025-02-09 19:25
parent: 
connected:
  - "#обс/linking"
tags:
  - fix/empty
  - fix/study_group
---

> [!tip] TF-IDF (Term Frequency-Inverse Document Frequency)
TF-IDF - это статистическая мера, используемая в обработке естественного языка (NLP) для оценки важности слова в документе относительно коллекции документов (корпуса). В отличие от простой модели Bag of Words (BoW), TF-IDF присваивает словам веса на основе их частоты в отдельном документе и во всем корпусе документов, подчеркивая редкие, но значимые термины.

### Компоненты TF-IDF

#### 1. Term Frequency (TF)
Измеряет, как часто термин встречается в документе.

**Формула**:
$${ TF(t, d) = \frac{f(t, d)}{\sum_k f(k, d)} }$$

где:
- $f(t, d)$ - частота термина $t$ в документе $d$
- $\sum_k f(k, d)$ - общее количество терминов в документе $d$

#### 2. Inverse Document Frequency (IDF)
Измеряет редкость термина во всем корпусе.

**Формула**:
$${ IDF(t, D) = \log\left(\frac{N}{1 + | \{ d \in D : t \in d \} |}\right) }$$

где:
- $N$ - общее количество документов в корпусе $D$
- $\left| \{ d \in D : t \in d \} \right|$ - количество документов, содержащих термин $t$
- 1 добавляется в знаменатель для избежания деления на ноль

#### 3. TF-IDF
Объединяет TF и IDF для вычисления веса термина в документе.

**Формула**:
$${ TF\text{-}IDF(t, d, D) = TF(t, d) \times IDF(t, D) }$$

### Ключевые свойства

#### Высокий вес получают:
- Термины, часто встречающиеся в документе, но редкие в корпусе
- Слова, специфичные для конкретного документа

#### Низкий вес получают:
- Общие термины, встречающиеся во многих документах
- Стоп-слова (например, "и", "или", "в")

### Применение

1. **Классификация текстов**
   - Обнаружение спама
   - Анализ тональности
   - Категоризация документов

2. **Информационный поиск**
   - [[Ranking]] документов по релевантности
   - Поисковые системы

3. **Извлечение ключевых слов**
   - Автоматическое реферирование
   - Выделение важных терминов

4. **Кластеризация и тематическое моделирование**
   - Векторное представление документов
   - Группировка похожих текстов

### Преимущества

- **Простота**: легко вычислять и интерпретировать
- **Эффективность**: хорошо отражает важность слов
- **Гибкость**: подходит для различных задач NLP
- **Интуитивность**: понятная математическая модель

### Ограничения

- **Отсутствие контекста**: игнорирует семантику и порядок слов
- **Разреженность**: большие разреженные матрицы для больших словарей
- **Масштабируемость**: менее эффективен для очень больших корпусов
- **Зависимость от словаря**: чувствителен к предобработке текста

### Итог
TF-IDF улучшает модель Bag of Words, взвешивая термины на основе их значимости в документе и редкости в корпусе. Остается фундаментальным методом в обработке текстов, особенно эффективным для небольших датасетов и классических задач NLP.