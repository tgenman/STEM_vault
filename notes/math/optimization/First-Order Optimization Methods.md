---
aliases: 
anki: false
created: 2024-12-19 13:27
parent:
  - "[[Gradient-Based Methods]]"
connected:
  - "#обс/linking"
tags:
  - content/empty
---

1. Метод сопряженных градиентов - это как навигатор, который:
- Требует точную карту местности
- Рассчитывает идеальный маршрут
- Работает отлично, когда дорога пустая и все улицы открыты

1. Метод моментов - это как опытный таксист, который:
- Примерно знает район
- Может объехать пробки
- Адаптируется к изменениям на дороге

```
# Метод сопряженных градиентов требует точных вычислений
# Но в реальности наши градиенты зашумлены:
реальный_градиент = истинный_градиент + случайный_шум

# Метод моментов лучше справляется с шумом:
v_t = 0.9 * v_previous + 0.1 * зашумленный_градиент
# Усреднение по времени уменьшает влияние шума
```


Почему же мы чаще используем метод моментов:

1. Стохастичность:

- В глубоком обучении мы используем мини-батчи
- Градиенты получаются зашумленными
- Метод сопряженных градиентов может "сбиться" из-за неточных градиентов

2. Вычислительная эффективность:

- Метод моментов требует только градиент
- Метод сопряженных градиентов требует точного линейного поиска, что дорого

1. Память:

- В глубоких сетях миллионы параметров
- Хранить точную информацию о предыдущих направлениях слишком накладно

2. Негладкость функции потерь:

- В глубоких сетях функция потерь не квадратичная и не гладкая
- Теоретические гарантии метода сопряженных градиентов перестают работать

Поэтому на практике:

- Для гладких задач оптимизации (например, обучение линейной регрессии) → метод сопряженных градиентов
- Для глубокого обучения → метод моментов или его модификации (Adam, РМSprop)