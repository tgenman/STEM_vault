---
aliases: 
anki: false
created: 2024-06-19 13:36
parent:
  - "[[Loss function]]"
connected:
  - "#обс/linking"
tags:
  - fix/empty
---


$$ \mathcal{L}(f, X, y) = \sum_{i=1}^{N} h_{\delta}(y_{i} - \langle w_{i}, x \rangle), \quad \text{где} \quad h_{\delta}(z) = \begin{cases} \frac{1}{2} z^{2}, & |z| \leq \delta \\ \delta (|z| - \frac{1}{2} \delta), & |z| > \delta \end{cases} $$

Число $\delta$ является гиперпараметром. Сложная формула при $|z| > \delta$ нужна, чтобы функция $h_{\delta}(z)$ была непрерывной. Попробуйте объяснить, зачем может быть нужна такая функция потерь.


Часто требования формулируют в духе «функция потерь должна слабее штрафовать то-то и сильней штрафовать вот это». Например, $L^{2}$-регуляризованный лосс штрафует за большие по модулю веса. В данном случае можно заметить, что при небольших значениях ошибки берётся просто MSE, а при больших мы начинаем штрафовать нашу модель менее сурово. Например, это может быть полезно для того, чтобы выбросы не так сильно влияли на результат обучения.
